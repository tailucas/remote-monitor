#!/usr/bin/env python
import copy
import dateutil.parser
import json
import logging
import logging.handlers
import netifaces
import os
import pytz
import signal
import sys
import threading
import time
import umsgpack
import zmq

from ADCPi import ADCPi
from IOPi import IOPi

from configparser import ConfigParser

from datetime import datetime
from random import randint
from raven import Client as Sentry
from threading import Thread
from time import sleep
from traceback import StackSummary
from zmq import ContextTerminated
from zmq.error import ZMQError

import botocore
import os.path
from botoflow import activity, \
    activities, \
    execute, \
    return_, \
    workflow_starter, \
    WorkflowDefinition, \
    ThreadedWorkflowExecutor, \
    ThreadedActivityExecutor
from botoflow.workers.workflow_worker import WorkflowWorker
from botoflow.workers.activity_worker import ActivityWorker
from botoflow.constants import SECONDS, MINUTES
from botoflow.exceptions import ActivityTaskFailedError, \
    WorkflowFailedError, WorkflowTimedOutError

APP = os.path.basename(__file__)
if sys.stdout.isatty() and os.system('systemctl status app') == 0:
    print("{} is already running. Use 'systemctl stop app' to stop first.".format(APP))
    sys.exit(1)

log = logging.getLogger(APP)
# no console by default
log.propagate = False

# FIXME: benchmark this to supply voltage using test pin or something else
ADC_SAMPLE_MAX = 5.0
HEARTBEAT_INTERVAL_SECONDS = 5
RELAY_DEFAULT_ACTIVE_TIME_SECONDS = 1
SAMPLE_INTERVAL_SECONDS = 0.1
SAMPLE_DEVIATION_TOLERANCE = 10
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'
URL_WORKER_UPLOADER = 'inproc://uploader'
URL_WORKER_RELAY_CTRL = 'inproc://relay-ctrl'
URL_WORKER_RELAY = 'inproc://relay-{}'


DIR = os.path.abspath(os.path.dirname(__file__))
config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

zmq_context = zmq.Context()
zmq_context.setsockopt(zmq.LINGER, 0)
shutting_down = False

sentry = Sentry()


def make_timestamp(timestamp=None, make_string=False):
    if timestamp is None:
        timestamp = datetime.utcnow()
    elif isinstance(timestamp, float) or isinstance(timestamp, int):
        timestamp = datetime.utcfromtimestamp(timestamp)
    elif isinstance(timestamp, str):
        timestamp = dateutil.parser.parse(timestamp)
    if make_string:
        return timestamp.strftime(DATE_FORMAT)
    # not naive datetime
    return timestamp.replace(tzinfo=pytz.utc)


@activities(schedule_to_start_timeout=1*MINUTES,
            start_to_close_timeout=1*MINUTES)
class IOBoardActivity(object):

    def __init__(self, zmq_url):
        self._zmq_url = zmq_url
        self._zmq_worker = None

    @activity(version='1.1', start_to_close_timeout=5*SECONDS)
    def trigger_output(self, device_key, delay):
        try:
            # create ZMQ socket and use on the correct thread
            if (self._zmq_worker is None):
                self._zmq_worker = zmq_context.socket(zmq.PUSH)
                self._zmq_worker.connect(self._zmq_url)
            self._zmq_worker.send_pyobj((device_key, delay))
        except Exception:
            log.exception(self.__class__.__name__)
            sentry.captureException()
            raise

    def stop(self):
        # create ZMQ socket and use on the correct thread
        if (self._zmq_worker is not None):
            self._zmq_worker.close()


class Uploader(Thread):

    def __init__(self):
        super(Uploader, self).__init__(name=self.__class__.__name__)
        self.daemon = True
        # inproc socket to accept messages to publish
        # to the outside world
        self.inproc_pull = zmq_context.socket(zmq.PULL)
        self.inproc_pull.bind(URL_WORKER_UPLOADER)

    def run(self):
        # Socket to talk to the outside world
        publisher = zmq_context.socket(zmq.PUB)
        try:
            publisher.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                      port=config.get('zmq', 'pubsub_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            raise

        while True:
            try:
                publisher.send(Uploader.make_payload(
                    timestamp=None,
                    data=self.inproc_pull.recv_pyobj()))
            except ContextTerminated:
                self.inproc_pull.close()
                publisher.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    @staticmethod
    def make_payload(timestamp=None, data=None):
        payload = {'timestamp': make_timestamp(timestamp, True)}
        if data is not None and len(data) > 0:
            payload['data'] = data
        log.debug(json.dumps(payload))
        return umsgpack.packb(payload)


class DeviceActivator(Thread):

    def __init__(self):
        super(DeviceActivator, self).__init__(name=self.__class__.__name__)
        self.daemon = True

        self.listener = zmq_context.socket(zmq.PULL)
        # what to do with device activations
        self.relay_control = zmq_context.socket(zmq.PUSH)

    def run(self):
        # outputs
        self.relay_control.connect(URL_WORKER_RELAY_CTRL)
        # Socket to talk to the outside world
        try:
            self.listener.bind('tcp://{ip}:{port}'.format(ip=config.get('app', 'eth0_ip'),
                                                          port=config.get('zmq', 'pushpull_port')))
        except ZMQError:
            log.exception(self.__class__.__name__)
            raise

        while True:
            try:
                event = umsgpack.unpackb(self.listener.recv())
                log.debug(event)
                if 'data' not in event:
                    log.warning('Unknown event data: {}'.format(event))
                    continue
                event_data = event['data']
                if 'trigger_output' in event_data:
                    output_type = event_data['trigger_output']['type']
                    if 'input_context' not in event_data:
                        log.warning('{} requested without context, ignoring.'.format(output_type))
                        continue
                    delay = None
                    if 'trigger_duration' in event_data:
                        delay = event_data['trigger_duration']
                    # send all output activations to the relay control, which will filter accordingly
                    self.relay_control.send_pyobj((event_data['trigger_output']['device_key'], delay))
            except ContextTerminated:
                self.listener.close()
                self.relay_control.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class Relay(Thread):

    def __init__(self, relay_name, io, pin):
        super(Relay, self).__init__()
        self.daemon = True
        self._name = relay_name
        self._io = io
        self._pin = pin
        self._zmq_url = URL_WORKER_RELAY.format(relay_name)
        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(self._zmq_url)

    @property
    def zmq_url(self):
        return self._zmq_url

    def run(self):
        while True:
            try:
                relay_ctrl = self.socket.recv_pyobj()
                if 'state' in relay_ctrl:
                    if relay_ctrl['state'] is True:
                        self._io.write_pin(self._pin, 1)
                        # sleep
                        if 'delay' in relay_ctrl:
                            delay = relay_ctrl['delay']
                        else:
                            delay = RELAY_DEFAULT_ACTIVE_TIME_SECONDS
                        log.info("Activating {} for {} seconds.".format(self._name, delay))
                        self._io.write_pin(self._pin, 1)
                        sleep(float(delay))
                    self._io.write_pin(self._pin, 0)
            except ContextTerminated:
                self.socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue


class RelayControl(Thread):

    def __init__(self, relay_mappings):
        super(RelayControl, self).__init__()
        self.daemon = True
        # Pull socket to receive relay control commands
        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_RELAY_CTRL)
        # Push socket to control relays
        self._sockets = dict()
        for relay, worker_url in list(relay_mappings.items()):
            socket = zmq_context.socket(zmq.PUSH)
            self._sockets[relay] = socket
            socket.connect(worker_url)
        self._output_to_relay = dict()

    def run(self):
        while True:
            try:
                device_key, delay = self.socket.recv_pyobj()
                log.debug("Relay event for '{}'".format(device_key))
                if device_key not in self._output_to_relay:
                    log.debug("'{}' is not configured for relay control".format(device_key))
                    continue
                relay = self._output_to_relay[device_key]
                if relay in self._sockets:
                    log.info("'{}' => '{}'".format(device_key, relay))
                    relay_cmd = {
                        'state': True
                    }
                    if delay:
                        relay_cmd['delay'] = delay
                    self._sockets[relay].send_pyobj(relay_cmd)
                else:
                    log.error("'{}' refers to non-existent relay '{}'".format(device_key, relay))
            except ContextTerminated:
                self.socket.close()
                for socket in list(self._sockets.values()):
                    socket.close()
                break
            except Exception:
                log.exception(self.__class__.__name__)
                sentry.captureException()
                sleep(1)
                continue

    def add_output(self, device_key, relay):
        if device_key in self._output_to_relay:
            raise RuntimeError('{} is already associated with {}. Cannot also associate {}.'.format(
                device_key,
                self._output_to_relay[device_key],
                relay))
        self._output_to_relay[device_key] = relay


class SignalHandler:

    def __init__(self):
        self.last_signal = 0
        signal.signal(signal.SIGTERM, self.terminate)
        signal.signal(signal.SIGHUP, self.hup)

    def hup(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        if log.getEffectiveLevel() == logging.INFO:
            log.setLevel(logging.DEBUG)
        elif log.getEffectiveLevel() == logging.DEBUG:
            log.setLevel(logging.INFO)

    def terminate(self, signum, frame):
        log.warning('Signal {} received.'.format(signum))
        self.last_signal = signum
        raise RuntimeWarning()


def thread_nanny(threads_tracked, signal_handler):
    global shutting_down
    while True:
        # kill the nanny now
        if signal_handler.last_signal == signal.SIGTERM:
            break
        threads_alive = set()
        for thread_info in threading.enumerate():
            if thread_info.isAlive():
                threads_alive.add(thread_info.getName())
        if len(threads_tracked - threads_alive) > 0:
            message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
            log.fatal(message)
            shutting_down = True
        else:
            sleep(10)


@activities(schedule_to_start_timeout=1*MINUTES,
            start_to_close_timeout=1*MINUTES)
class DeviceInfoActivity(object):

    @activity(version='1.1', start_to_close_timeout=5*SECONDS)
    def get_ip_address(self):
        ipv4_address = None
        lan_iface = None
        default_gateway_ipv4_iface = None
        # use the gateway data to find the LAN device from which IP is determined
        default_gateway_ipv4 = netifaces.gateways()['default'][netifaces.AF_INET]
        if default_gateway_ipv4 is not None and len(default_gateway_ipv4) > 0:
            default_gateway_ipv4_address = default_gateway_ipv4[0]
            default_gateway_ipv4_iface = default_gateway_ipv4[1]
            log.info('Gateway address is {} on {}'.format(default_gateway_ipv4_address, default_gateway_ipv4_iface))
            lan_iface = default_gateway_ipv4_iface
        else:
            # go old-skool
            ifaces = netifaces.interfaces()
            # put wlan at the end
            ifaces.sort()
            for iface in ifaces:
                if iface.lower().startswith(("et", "en", "wlan")):
                    try:
                        netifaces.ifaddresses(iface)[netifaces.AF_INET]
                    except KeyError:
                        next
                    lan_iface = iface
                    break
        ipv4_address = netifaces.ifaddresses(lan_iface)[netifaces.AF_INET][0]['addr']
        log.info('Using IPv4 address {} on {}'.format(ipv4_address, lan_iface))
        return ipv4_address


def swf_exception_handler(err: Exception, tb_list: StackSummary):
    global shutting_down
    log.fatal('SWF processing exception: {} {}'.format(err, tb_list.format()))
    shutting_down = True


if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.INFO)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        stream_handler.setFormatter(formatter)
        log.addHandler(stream_handler)

    # connect to SWF
    boto_session = botocore.session.Session(profile=config.get('botoflow', 'profile'))
    swf_activity = IOBoardActivity(URL_WORKER_RELAY_CTRL)
    swf_worker = ThreadedActivityExecutor(ActivityWorker(boto_session,
                                            config.get('botoflow', 'region'),
                                            config.get('botoflow', 'domain'),
                                            APP,
                                            swf_activity, DeviceInfoActivity()))
    swf_worker._worker.unhandled_exception_handler = swf_exception_handler
    swf_worker.start()

    # process configuration
    adcs = dict()
    for adc, address in config.items('adc_address'):
        log.info("Configuring '{}' @ '{}'".format(adc, address))
        address = address.split(',')
        adcs[adc] = ADCPi(int(address[0], 16),
                          int(address[1], 16),
                          12)

    ios = dict()
    for io, address in config.items('io_address'):
        log.info("Configuring '{}' @ '{}'".format(io, address))
        io_port = IOPi(int(address, 16))
        # set port direction to output
        io_port.set_port_direction(0, 0x00)
        io_port.set_port_direction(1, 0x00)
        # zero all pins
        io_port.write_port(0, 0x00)
        io_port.write_port(1, 0x00)
        ios[io] = io_port

    relay_to_io = dict()
    for relay, address in config.items('relay_address'):
        io, pin = tuple(address.split(':'))
        relay_to_io[relay] = (io, int(pin))
        log.info("Mapped '{}' to IO '{}' on pin {}".format(relay, io, pin))

    threads_tracked = set()

    relay_workers = list()
    relay_to_worker = dict()
    # start relays
    for relay_name in list(relay_to_io.keys()):
        io, pin = relay_to_io[relay_name]
        relay = Relay(relay_name=relay_name, io=ios[io], pin=pin)
        relay.start()
        threads_tracked.add(relay.getName())
        relay_workers.append(relay)
        relay_to_worker[relay_name] = relay.zmq_url

    relay_control = RelayControl(relay_mappings=relay_to_worker)

    input_types = dict(config.items('input_type'))
    # name overrides location name
    input_names = dict(config.items('input_name'))
    input_locations = dict(config.items('input_location'))
    # construct the device representation
    input_devices = dict()
    output_types = dict(config.items('output_type'))
    output_locations = dict(config.items('output_location'))
    device_info = dict()
    device_info['inputs'] = list()
    for field, input_type in list(input_types.items()):
        input_name = input_names[field]
        input_location = input_locations[field]
        device_description = {
            'name': input_name,
            'type': input_type,
            'location': input_location,
            'device_key': '{} {} ({})'.format(input_name, input_type, input_location),
            'device_label': '{} {}'.format(input_name, input_type)
        }
        device_info['inputs'].append(device_description)
        input_devices[field] = device_description
    device_info['outputs'] = list()
    for field, output_type in list(output_types.items()):
        output_location = output_locations[field]
        device_key = '{} {}'.format(output_location, output_type)
        device_info['outputs'].append({
            'type': output_type,
            'location': output_location,
            'device_key': device_key
        })
        if config.has_option('output_relay', field):
            relay = config.get('output_relay', field)
            log.info("'{}' will trigger '{}'".format(device_key, relay))
            relay_control.add_output(
                device_key=device_key,
                relay=relay)

    input_addresses = dict(config.items('input_address'))
    input_to_adc = dict()
    for field in input_addresses:
        adc, pin = tuple(input_addresses[field].split(':'))
        input_to_adc[field] = (adc, int(pin))
        # get the normal value
        log.info("ADC {} pin {} will detect '{}'".format(adc, pin, input_devices[field]['device_key']))

    # start up threads
    uploader = Uploader()
    uploader.start()
    threads_tracked.add(uploader.getName())
    uploader_socket = zmq_context.socket(zmq.PUSH)
    uploader_socket.connect(URL_WORKER_UPLOADER)

    # start relay control
    relay_control.start()
    threads_tracked.add(relay_control.getName())

    device_activator = DeviceActivator()
    device_activator.start()
    threads_tracked.add(device_activator.getName())

    samples_processed = 0

    input_normal_values = dict(config.items('input_normal_values'))
    tamper_label = config.get('app', 'tamper_label')
    input_tamper_values = dict(config.items('input_tamper_values'))

    # set up signal handlers
    signal_handler = SignalHandler()
    f = threading.Thread(name='nanny', target=thread_nanny, args=(threads_tracked, signal_handler,))
    f.setDaemon(True)
    f.start()

    try:
        last_upload = 0
        device_history = dict()
        while not shutting_down:
            active_devices = list()
            output_samples = dict()
            for i in list(input_to_adc.keys()):
                adc_name, pin = input_to_adc[i]
                try:
                    sampled_value = adcs[adc_name].read_voltage(pin)
                except TimeoutError:
                    log.warning('Timeout reading value from {} on pin {}.'.format(adc_name, pin), exc_info=1)
                    sleep(1)
                    continue
                normalized_value = (sampled_value / ADC_SAMPLE_MAX) * 100
                input_value = int(input_normal_values[i])
                device_key = input_devices[i]['device_key']
                device_type = input_devices[i]['type']
                samples_processed += 1
                if randint(0, 1000) < SAMPLE_INTERVAL_SECONDS * 1000:
                    log.debug('Comparing {}.{}={} ({}v) '
                              'to {} ({}) (tolerance: {})'.format(adc_name,
                                                                  pin,
                                                                  normalized_value,
                                                                  sampled_value,
                                                                  input_value,
                                                                  device_key,
                                                                  SAMPLE_DEVIATION_TOLERANCE))
                if abs(normalized_value - input_value) <= SAMPLE_DEVIATION_TOLERANCE:
                    # forget that this device was active
                    if device_key in device_history:
                        log.debug("'{}' is no longer active.".format(device_key))
                        del device_history[device_key]
                    # nothing else to unset here, next input now
                    continue

                # a device has now gone out of normal range
                device_event_distinction = device_key
                output_samples[device_key] = int(normalized_value)
                input_device = copy.copy(input_devices[i])
                input_device['sample_value'] = int(normalized_value)
                event_detail = None
                if i in input_tamper_values:
                    tamper_value = int(input_tamper_values[i])
                    if abs(normalized_value - tamper_value) <= SAMPLE_DEVIATION_TOLERANCE:
                        event_detail = tamper_label
                        device_event_distinction = '{} {}'.format(device_key, tamper_label)
                # now include the event detail
                if event_detail:
                    input_device['event_detail'] = event_detail
                # determine whether the value has changed
                if device_key in device_history:
                    historic_value, sampled_at, historic_detail = device_history[device_key]
                    # has the value stayed the same?
                    if abs(normalized_value - historic_value) <= SAMPLE_DEVIATION_TOLERANCE and event_detail == historic_detail:
                        # sample to avoid log spam
                        if randint(0, 1000) < SAMPLE_INTERVAL_SECONDS * 1000:
                            log.debug("Debouncing '{}' (detail: {}) activated {} seconds "
                                      "ago.".format(device_event_distinction, event_detail,
                                                    int(time.time() - sampled_at)))
                        continue
                # update the device history and treat as active
                device_history[device_key] = (normalized_value, time.time(), event_detail)
                # add the input device to the 'active' list
                active_devices.append(input_device)
                log.info("'{}' (detail: {}, sampled: {})".format(device_event_distinction, event_detail, normalized_value))
            if len(active_devices) > 0:
                uploader_socket.send_pyobj({
                    'samples': output_samples,
                    'active_devices': active_devices
                })
                last_upload = time.time()
            else:
                inactivity = time.time() - last_upload
                if inactivity > HEARTBEAT_INTERVAL_SECONDS:
                    uploader_socket.send_pyobj({
                        'statistics': {'sample_count': samples_processed},
                        'device_info': device_info
                    })
                    last_upload = time.time()
            sleep(SAMPLE_INTERVAL_SECONDS)
        raise RuntimeWarning("Shutting down...")
    except(KeyboardInterrupt, RuntimeWarning, ContextTerminated) as e:
        message = "Shutting down {}..."
        log.info(message.format('SWF activity worker'))
        swf_worker.stop()
        swf_worker.join()
        log.info(message.format('SWF activity channel'))
        # stop SWF activity to close ZMQ channel
        swf_activity.stop()
        log.info(message.format('Application threads'))
        uploader_socket.close()
        log.info(message.format('ZMQ context'))
        zmq_context.term()
        log.info(message.format('SWF worker'))
        swf_worker.join()
        log.info('Shutdown complete.')